{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pWo66Dk0HhY0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback ,EarlyStopping,ModelCheckpoint\n",
    "from sklearn.metrics import precision_score, recall_score,accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU, Bidirectional, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52wwxY_4Mu3Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OKRdeWSrDBfO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\admin\\Desktop\\Major project\\dataset\\cleanDataOne.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3GwCnGAFlOG",
    "outputId": "b1a827d1-b97d-449e-e5ce-3fe0fe946ec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             cocksucker before you piss around on my work\n",
       "1        bye do not look come or think of comming back ...\n",
       "2                   fuck your filthy mother in the ass dry\n",
       "3        get fucked up get fuckeeed up  got a drink tha...\n",
       "4        stupid peace of shit stop deleting my stuff as...\n",
       "                               ...                        \n",
       "18049    nothing of the sort  sumple and i are merely t...\n",
       "18050    actually i broke a bone before  twice actually...\n",
       "18051    ankit fadia study award updated the source for...\n",
       "18052                           your sources are worthless\n",
       "18053    this was the first time for me  it was very hi...\n",
       "Name: text, Length: 18054, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "qb0HyFz-GUed",
    "outputId": "3b046cdd-af01-492b-9415-46d89803bc60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bye do not look come or think of comming back ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuck your filthy mother in the ass dry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get fucked up get fuckeeed up  got a drink tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stupid peace of shit stop deleting my stuff as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18049</th>\n",
       "      <td>nothing of the sort  sumple and i are merely t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18050</th>\n",
       "      <td>actually i broke a bone before  twice actually...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18051</th>\n",
       "      <td>ankit fadia study award updated the source for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18052</th>\n",
       "      <td>your sources are worthless</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18053</th>\n",
       "      <td>this was the first time for me  it was very hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18054 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  y\n",
       "0           cocksucker before you piss around on my work  1\n",
       "1      bye do not look come or think of comming back ...  1\n",
       "2                 fuck your filthy mother in the ass dry  1\n",
       "3      get fucked up get fuckeeed up  got a drink tha...  1\n",
       "4      stupid peace of shit stop deleting my stuff as...  1\n",
       "...                                                  ... ..\n",
       "18049  nothing of the sort  sumple and i are merely t...  0\n",
       "18050  actually i broke a bone before  twice actually...  0\n",
       "18051  ankit fadia study award updated the source for...  0\n",
       "18052                         your sources are worthless  0\n",
       "18053  this was the first time for me  it was very hi...  0\n",
       "\n",
       "[18054 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR7JKfLBHAaZ",
    "outputId": "c0de06ab-7d73-46be-d555-a3838d14b6e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df['text'].astype(str)\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr_fQUd4Eg-8"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vALUmamG3tm",
    "outputId": "cdb187b7-40ca-4a36-bfaf-ffffb764f615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.49886     0.76602     0.89750999 ... -0.41179001  0.40538999\n",
      "   0.78504002]\n",
      " [-0.038194   -0.24487001  0.72812003 ... -0.1459      0.82779998\n",
      "   0.27061999]\n",
      " ...\n",
      " [ 0.30746001  0.0071693  -0.40382999 ...  0.16892    -0.75593001\n",
      "  -0.13414   ]\n",
      " [ 0.050396   -0.43832001 -0.26798999 ...  0.019003   -0.6778\n",
      "  -0.30882999]\n",
      " [ 0.12239     0.40292999 -0.42792001 ...  0.57059002 -0.23425999\n",
      "   0.17585   ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_arr = np.load(r'C:\\Users\\admin\\Desktop\\Major project\\embeddingsArray.npy')\n",
    "\n",
    "# print the loaded array\n",
    "print(loaded_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TQtW6hlPHgvg"
   },
   "outputs": [],
   "source": [
    "embedding_matrix=loaded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JqZGUPiZExN8"
   },
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision(name='precision')\n",
    "recall = tf.keras.metrics.Recall(name='recall')\n",
    "early_stop=EarlyStopping(monitor='val_loss',patience=5)\n",
    "checkpoint = ModelCheckpoint('model_weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mKyhgGIQdPho"
   },
   "outputs": [],
   "source": [
    "modelGRUBidirectionalGlove = Sequential()\n",
    "modelGRUBidirectionalGlove.add(Embedding(input_dim=26611, output_dim=100,weights=[embedding_matrix],trainable=False))\n",
    "\n",
    "modelGRUBidirectionalGlove.add(Bidirectional(GRU(64)))\n",
    "modelGRUBidirectionalGlove.add(Dense(1, activation='sigmoid'))\n",
    "modelGRUBidirectionalGlove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',precision,recall])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AqlaZrEpipTH"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, df['y'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Igo1Sv09gz98",
    "outputId": "2c9ca626-3d61-4456-d484-6625f2067d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.3356 - accuracy: 0.8574 - precision: 0.8669 - recall: 0.8445\n",
      "Epoch 1: val_loss improved from inf to 0.27309, saving model to model_weights.h5\n",
      "452/452 [==============================] - 24s 46ms/step - loss: 0.3356 - accuracy: 0.8574 - precision: 0.8669 - recall: 0.8445 - val_loss: 0.2731 - val_accuracy: 0.8851 - val_precision: 0.8986 - val_recall: 0.8682\n",
      "Epoch 2/30\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.2566 - accuracy: 0.8964 - precision: 0.9027 - recall: 0.8886\n",
      "Epoch 2: val_loss improved from 0.27309 to 0.26259, saving model to model_weights.h5\n",
      "452/452 [==============================] - 21s 47ms/step - loss: 0.2566 - accuracy: 0.8965 - precision: 0.9028 - recall: 0.8887 - val_loss: 0.2626 - val_accuracy: 0.8914 - val_precision: 0.8675 - val_recall: 0.9241\n",
      "Epoch 3/30\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9069 - precision: 0.9112 - recall: 0.9017\n",
      "Epoch 3: val_loss improved from 0.26259 to 0.25359, saving model to model_weights.h5\n",
      "452/452 [==============================] - 23s 51ms/step - loss: 0.2350 - accuracy: 0.9069 - precision: 0.9113 - recall: 0.9017 - val_loss: 0.2536 - val_accuracy: 0.8967 - val_precision: 0.8745 - val_recall: 0.9264\n",
      "Epoch 4/30\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9121 - precision: 0.9169 - recall: 0.9065\n",
      "Epoch 4: val_loss improved from 0.25359 to 0.24127, saving model to model_weights.h5\n",
      "452/452 [==============================] - 22s 48ms/step - loss: 0.2184 - accuracy: 0.9122 - precision: 0.9169 - recall: 0.9065 - val_loss: 0.2413 - val_accuracy: 0.9061 - val_precision: 0.8916 - val_recall: 0.9247\n",
      "Epoch 5/30\n",
      "451/452 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9195 - precision: 0.9230 - recall: 0.9153\n",
      "Epoch 5: val_loss improved from 0.24127 to 0.23674, saving model to model_weights.h5\n",
      "452/452 [==============================] - 24s 53ms/step - loss: 0.2051 - accuracy: 0.9194 - precision: 0.9230 - recall: 0.9151 - val_loss: 0.2367 - val_accuracy: 0.9061 - val_precision: 0.9218 - val_recall: 0.8876\n",
      "Epoch 6/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9279 - precision: 0.9323 - recall: 0.9227\n",
      "Epoch 6: val_loss improved from 0.23674 to 0.23563, saving model to model_weights.h5\n",
      "452/452 [==============================] - 23s 52ms/step - loss: 0.1865 - accuracy: 0.9279 - precision: 0.9323 - recall: 0.9227 - val_loss: 0.2356 - val_accuracy: 0.9034 - val_precision: 0.9113 - val_recall: 0.8937\n",
      "Epoch 7/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9329 - precision: 0.9363 - recall: 0.9290\n",
      "Epoch 7: val_loss did not improve from 0.23563\n",
      "452/452 [==============================] - 24s 53ms/step - loss: 0.1726 - accuracy: 0.9329 - precision: 0.9363 - recall: 0.9290 - val_loss: 0.2469 - val_accuracy: 0.9009 - val_precision: 0.9284 - val_recall: 0.8688\n",
      "Epoch 8/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.9392 - precision: 0.9450 - recall: 0.9327\n",
      "Epoch 8: val_loss did not improve from 0.23563\n",
      "452/452 [==============================] - 24s 53ms/step - loss: 0.1585 - accuracy: 0.9392 - precision: 0.9450 - recall: 0.9327 - val_loss: 0.2700 - val_accuracy: 0.9036 - val_precision: 0.9355 - val_recall: 0.8671\n",
      "Epoch 9/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9493 - precision: 0.9552 - recall: 0.9428\n",
      "Epoch 9: val_loss did not improve from 0.23563\n",
      "452/452 [==============================] - 23s 51ms/step - loss: 0.1394 - accuracy: 0.9493 - precision: 0.9552 - recall: 0.9428 - val_loss: 0.2594 - val_accuracy: 0.9053 - val_precision: 0.9026 - val_recall: 0.9086\n",
      "Epoch 10/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9541 - precision: 0.9591 - recall: 0.9486\n",
      "Epoch 10: val_loss did not improve from 0.23563\n",
      "452/452 [==============================] - 22s 49ms/step - loss: 0.1221 - accuracy: 0.9541 - precision: 0.9591 - recall: 0.9486 - val_loss: 0.2790 - val_accuracy: 0.9061 - val_precision: 0.9073 - val_recall: 0.9048\n",
      "Epoch 11/30\n",
      "452/452 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9616 - precision: 0.9650 - recall: 0.9580\n",
      "Epoch 11: val_loss did not improve from 0.23563\n",
      "452/452 [==============================] - 23s 51ms/step - loss: 0.1050 - accuracy: 0.9616 - precision: 0.9650 - recall: 0.9580 - val_loss: 0.2911 - val_accuracy: 0.9061 - val_precision: 0.9028 - val_recall: 0.9103\n"
     ]
    }
   ],
   "source": [
    "history=modelGRUBidirectionalGlove.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=30,batch_size=32,callbacks=[early_stop,checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "05p0P5OwhjhH"
   },
   "outputs": [],
   "source": [
    "gru_bidirectional_Glove_pickle_data={'data':history.history,'model':modelGRUBidirectionalGlove}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Yh4Z8VXOhh3m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\bidirectional\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\backward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\forward_layer\n",
      "......vars\n",
      "...layers\\bidirectional\\forward_layer\\cell\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      "...layers\\bidirectional\\layer\n",
      "......vars\n",
      "...layers\\bidirectional\\layer\\cell\n",
      "......vars\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\embedding\n",
      "......vars\n",
      ".........0\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\precision\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\recall\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-04-14 10:10:53         2718\n",
      "metadata.json                                  2023-04-14 10:10:53           64\n",
      "variables.h5                                   2023-04-14 10:10:53     11453128\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model object to a file\n",
    "with open(r'C:\\Users\\admin\\Desktop\\Major project\\dataset\\modelGRUBidirectionalGlove.pkl', 'wb') as f:\n",
    "    pickle.dump(gru_bidirectional_Glove_pickle_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
